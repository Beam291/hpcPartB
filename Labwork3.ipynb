{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labwork 3\n",
    "This new labwork focuses on the SCAN pattern, which is the Swiss-knife of the little parallel programmer..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "In this exercise, you must implement a **block-scan**. \n",
    "It is a scan into a single block, for a small amount of data (256 values). \n",
    "Then, you should implement the PRAM algorithm, with the correct per-warp synchronizations...\n",
    "\n",
    "NB: you must write the three device functions:\n",
    "- `load_shared_memory`\n",
    "- `pointer_jumping`\n",
    "- `save_shared_memory`\n",
    "The kernel should be read, too..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel computation time is 601.7098999023438 ms\n",
      "- seems to work\n",
      "kernel computation time is 236.2510986328125 ms\n",
      "- seems to work\n",
      "kernel computation time is 167.29510498046875 ms\n",
      "- seems to work\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "from numba.np.numpy_support import from_dtype\n",
    "from numba import cuda, core\n",
    "\n",
    "\n",
    "class BlockScan(object):\n",
    "    \"\"\"Create a scan object that scans values using a given binary\n",
    "    function. The binary function is compiled once and cached inside this\n",
    "    object. Keeping this object alive will prevent re-compilation.\n",
    "\n",
    "    The scan is functional for a limited number of values, as it runs into a single block.\n",
    "    THe number of values should be less than 256.\n",
    "    \"\"\"\n",
    "\n",
    "    _cache = {}\n",
    "\n",
    "    _WARP_SIZE = 32\n",
    "    _NUM_WARPS = 8\n",
    "\n",
    "    @staticmethod\n",
    "    def _gpu_kernel_factory(fn, np_type):\n",
    "        \"\"\"Factory of kernels for the block-scan problem...\n",
    "\n",
    "        This function returns a Cuda Kernel that does block-scan of some data using a given binary functor.\"\"\"\n",
    "\n",
    "        scan_op = cuda.jit(device=True)(fn)\n",
    "\n",
    "        max_block_size = BlockScan._NUM_WARPS * BlockScan._WARP_SIZE\n",
    "\n",
    "        @cuda.jit(device=True)\n",
    "        def load_shared_memory(shared_memory, d_input):\n",
    "            local_tid = cuda.threadIdx.x\n",
    "            # TODO: load data into shared memory\n",
    "            if local_tid < d_input.size:\n",
    "                shared_memory[local_tid] = d_input[local_tid]\n",
    "            cuda.syncthreads()\n",
    "\n",
    "        @cuda.jit(device=True)\n",
    "        def pointer_jumping(shared_memory, jump):\n",
    "            tid = cuda.threadIdx.x\n",
    "            if tid+ jump < cuda.blockDim.x:\n",
    "                temp = shared_memory[tid+ jump]\n",
    "            cuda.syncthreads()\n",
    "            if tid + jump < cuda.blockDim.x:\n",
    "                shared_memory[tid + jump] = scan_op(shared_memory[tid], temp)\n",
    "            cuda.syncthreads()\n",
    "\n",
    "        @cuda.jit(device=True)\n",
    "        def save_shared_memory(shared_memory, d_input):\n",
    "            local_tid = cuda.threadIdx.x\n",
    "            # TODO: save data from shared memory\n",
    "            if local_tid < d_input.size:\n",
    "                d_input[local_tid] = shared_memory[local_tid]\n",
    "\n",
    "        def gpu_scan_block(d_input):\n",
    "            \"\"\"\n",
    "            Per block SCAN...\n",
    "            \"\"\"\n",
    "            # move data to shared memory\n",
    "            shared_memory = cuda.shared.array(shape=max_block_size, dtype=np_type)\n",
    "            load_shared_memory(shared_memory, d_input)\n",
    "            \n",
    "            # TODO: implements the logics\n",
    "            jump = 1\n",
    "            while jump < cuda.blockDim.x:\n",
    "                pointer_jumping(shared_memory, jump) \n",
    "                jump *= 2\n",
    "                \n",
    "            save_shared_memory(shared_memory, d_input)\n",
    "\n",
    "        return cuda.jit(gpu_scan_block)\n",
    "\n",
    "    def __init__(self, functor):\n",
    "        \"\"\"\n",
    "        :param functor: A function implementing a binary operation for\n",
    "                        scan. It will be compiled as a CUDA device\n",
    "                        function using ``cuda.jit(device=True)``.\n",
    "        \"\"\"\n",
    "        self._functor = functor\n",
    "\n",
    "    def _compile(self, dtype):\n",
    "        key = self._functor, dtype\n",
    "        if key not in self._cache:\n",
    "            self._cache[key] = BlockScan._gpu_kernel_factory(self._functor, from_dtype(dtype))\n",
    "        return self._cache[key]\n",
    "\n",
    "    def __call__(self, d_input, res=None, stream=cuda.default_stream()):\n",
    "        \"\"\" Performs a per-block SCAN.\n",
    "\n",
    "        :param d_input: A host or device array.\n",
    "        :param stream: Optional CUDA stream in which to perform the scan.\n",
    "                    If no stream is specified, the default stream of 0 is used.\n",
    "        \"\"\"\n",
    "\n",
    "        # ensure 1d array\n",
    "        if d_input.ndim != 1:\n",
    "            raise TypeError(\"only support 1D array\")\n",
    "\n",
    "        # ensure size > 0\n",
    "        if d_input.size < 1:\n",
    "            raise ValueError(\"array's length is 0\")\n",
    "\n",
    "        # ensure size < 256\n",
    "        max_block_size = BlockScan._WARP_SIZE * BlockScan._NUM_WARPS\n",
    "        if d_input.size < max_block_size:\n",
    "            raise ValueError(\"array's length is greater than max block size\")\n",
    "\n",
    "        _sav, core.config.CUDA_LOW_OCCUPANCY_WARNINGS = core.config.CUDA_LOW_OCCUPANCY_WARNINGS, False\n",
    "\n",
    "        kernel = self._compile(d_input.dtype)\n",
    "\n",
    "        # Perform the reduction on the GPU\n",
    "        start_event = cuda.event(True)\n",
    "        start_event.record(stream=stream)\n",
    "        nb_threads = max_block_size\n",
    "\n",
    "        nb_blocks = 1\n",
    "\n",
    "        kernel[nb_blocks, nb_threads, stream](d_input)\n",
    "\n",
    "        stop_event = cuda.event(True)\n",
    "        stop_event.record(stream=stream)\n",
    "        stop_event.synchronize()\n",
    "        ct = cuda.event_elapsed_time(start_event, stop_event)\n",
    "        print(f\"kernel computation time is {ct} ms\")\n",
    "\n",
    "        core.config.CUDA_LOW_OCCUPANCY_WARNINGS = _sav\n",
    "\n",
    "        return d_input.copy_to_host()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    def iscan(array, zero):\n",
    "        sum = zero\n",
    "        for i in range(array.size):\n",
    "            sum += array[i]\n",
    "            array[i] = sum\n",
    "\n",
    "\n",
    "    def display(array):\n",
    "        for i in range(array.size):\n",
    "            print(f\"{array[i]} \", end=\"\")\n",
    "            if (i % 16) == 15:\n",
    "                print(\"\")\n",
    "\n",
    "\n",
    "    def check(expected, result):\n",
    "        it_works = True\n",
    "        for i in range(result.size):\n",
    "            if expected[i] != result[i]:\n",
    "                it_works = False\n",
    "        if it_works:\n",
    "            print(f'- seems to work')\n",
    "        else:\n",
    "            print(f'- seems to not work, here is your result:')\n",
    "            display(result)\n",
    "\n",
    "\n",
    "    def test_int32(size):\n",
    "        scanner = BlockScan(lambda a, b: a + b)\n",
    "        h_array = np.ones(size, dtype=np.int32)\n",
    "        result = scanner(cuda.to_device(h_array))\n",
    "        iscan(h_array, np.int32(0))\n",
    "        check(h_array, result)\n",
    "\n",
    "\n",
    "    def test_float32(size):\n",
    "        scanner = BlockScan(lambda a, b: a + b)\n",
    "        h_array = np.ones(size, dtype=np.float32)\n",
    "        result = scanner(cuda.to_device(h_array))\n",
    "        iscan(h_array, np.float32(0))\n",
    "        check(h_array, result)\n",
    "\n",
    "\n",
    "    def test_float64(size):\n",
    "        scanner = BlockScan(lambda a, b: a + b)\n",
    "        h_array = np.ones(size, dtype=np.float64)\n",
    "        result = scanner(cuda.to_device(h_array))\n",
    "        iscan(h_array, np.float64(0))\n",
    "        check(h_array, result)\n",
    "\n",
    "\n",
    "    test_int32(1 << 8)\n",
    "    test_float32(1 << 8)\n",
    "    test_float64(1 << 8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "This exercise deals with a block SCAN, but here applying the **hybrid** strategy saw in lecture 3. \n",
    "\n",
    "The idea is then (for a single block):\n",
    "- to load the data in shared memory\n",
    "- to do a SCAN per warp (so without warp synchronization)\n",
    "- to do a warp synchronization\n",
    "- to do a SCAN considering the last value of each warp (into a single warp, so no warp synchronization)\n",
    "- to do a warp synchronization\n",
    "- to apply the final MAP for all warps except the first...\n",
    "\n",
    "Try this wonderful strategy below.\n",
    "\n",
    "NB: the computation time will be roughly speaking the same, but the idea is to apply this algorithm in simple condition first, before to do it at a larger scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel computation time is 0.08009599894285202 ms\n",
      "- seems to work\n",
      "kernel computation time is 0.07807999849319458 ms\n",
      "- seems to work\n",
      "kernel computation time is 0.08070400357246399 ms\n",
      "- seems to work\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "from numba.np.numpy_support import from_dtype\n",
    "from numba import cuda, core\n",
    "\n",
    "\n",
    "class BlockScanHybrid(object):\n",
    "    \"\"\"Create a scan object that scans values using a given binary\n",
    "    function. The binary function is compiled once and cached inside this\n",
    "    object. Keeping this object alive will prevent re-compilation.\n",
    "\n",
    "    The scan is functional for a limited number of values, as it runs into a single block.\n",
    "    THe number of values should be less than 256.\n",
    "    \"\"\"\n",
    "\n",
    "    _cache = {}\n",
    "\n",
    "    _WARP_SIZE = 32\n",
    "    _NUM_WARPS = 8\n",
    "\n",
    "    @staticmethod\n",
    "    def _gpu_kernel_factory(fn, np_type):\n",
    "        \"\"\"Factory of kernels for the block-scan problem...\n",
    "\n",
    "        This function returns a Cuda Kernel that does block-scan of some data using a given binary functor.\"\"\"\n",
    "\n",
    "        scan_op = cuda.jit(device=True)(fn)\n",
    "\n",
    "        max_block_size = BlockScanHybrid._NUM_WARPS * BlockScanHybrid._WARP_SIZE\n",
    "        \n",
    "        @cuda.jit(device=True)\n",
    "        def load_shared_memory(shared_memory, d_input):\n",
    "            local_tid = cuda.threadIdx.x\n",
    "            # TODO: load data into shared memory\n",
    "            if local_tid < d_input.size:\n",
    "                shared_memory[local_tid] = d_input[local_tid]\n",
    "            cuda.syncthreads()\n",
    "\n",
    "        @cuda.jit(device=True)\n",
    "        def scan_per_warp(shared_memory):\n",
    "            tid = cuda.threadIdx.x\n",
    "            warp_tid = tid & 31\n",
    "            # TODO: per warp scan\n",
    "            jump = 1\n",
    "            while jump <32:\n",
    "                if warp_tid + jump <32:\n",
    "                    temp = shared_memory[tid]\n",
    "                cuda.syncwarp()\n",
    "                if warp_tid + jump <32:\n",
    "                    shared_memory[tid+jump] = scan_op(temp, shared_memory[tid + jump])\n",
    "                cuda.syncwarp()\n",
    "                jump *= 2\n",
    "\n",
    "        @cuda.jit(device=True)\n",
    "        def get_extra_value(shared_memory, last):\n",
    "            tid = cuda.threadIdx.x\n",
    "            warp_tid = tid & 31\n",
    "            # TODO: collect last value of each warp (copy into \"last\")\n",
    "            if warp_tid == 31:\n",
    "                warp_id = tid >> 5\n",
    "                last[warp_id] = shared_memory[tid]\n",
    "            cuda.syncthreads()\n",
    "            \n",
    "\n",
    "        @cuda.jit(device=True)\n",
    "        def apply_final_map(shared_memory, last):\n",
    "            tid = cuda.threadIdx.x\n",
    "            warp_id = tid >> 5\n",
    "            # TODO: apply final MAP\n",
    "            if warp_id > 0:\n",
    "                value = last[warp_id -1]\n",
    "                shared_memory[tid] = scan_op(value, shared_memory[tid])\n",
    "        @cuda.jit(device=True)\n",
    "        def save_shared_memory(shared_memory, d_output):\n",
    "            local_tid = cuda.threadIdx.x\n",
    "            # TODO: save data from shared memory\n",
    "            if local_tid < d_output.size:\n",
    "                d_output[local_tid] = shared_memory[local_tid]\n",
    "\n",
    "        def gpu_scan_block(d_input, d_output):\n",
    "            \"\"\"\n",
    "            Per block SCAN...\n",
    "            \"\"\"\n",
    "            # move data to shared memory\n",
    "            shared_memory = cuda.shared.array(shape=max_block_size, dtype=np_type)\n",
    "            extra_shared_memory = cuda.shared.array(shape=32, dtype=np_type)\n",
    "            load_shared_memory(shared_memory, d_input)\n",
    "\n",
    "            # TODO: implements the logics\n",
    "            scan_per_warp(shared_memory)\n",
    "            cuda.syncthreads()\n",
    "            get_extra_value(shared_memory, extra_shared_memory)\n",
    "            if cuda.threadIdx.x < 32:\n",
    "                scan_per_warp(extra_shared_memory)\n",
    "            cuda.syncthreads()\n",
    "            apply_final_map(shared_memory, extra_shared_memory)\n",
    "            \n",
    "            save_shared_memory(shared_memory, d_output)\n",
    "#             get_extra_value(shared_memory, extra_shared_memory)\n",
    "        return cuda.jit(gpu_scan_block)\n",
    "\n",
    "    def __init__(self, functor):\n",
    "        \"\"\"\n",
    "        :param functor: A function implementing a binary operation for\n",
    "                        scan. It will be compiled as a CUDA device\n",
    "                        function using ``cuda.jit(device=True)``.\n",
    "        \"\"\"\n",
    "        self._functor = functor\n",
    "\n",
    "    def _compile(self, dtype):\n",
    "        key = self._functor, dtype\n",
    "        if key not in self._cache:\n",
    "            self._cache[key] = BlockScanHybrid._gpu_kernel_factory(self._functor, from_dtype(dtype))\n",
    "        return self._cache[key]\n",
    "\n",
    "    def __call__(self, d_input, d_output=None, stream=cuda.default_stream()):\n",
    "        \"\"\" Performs a per-block SCAN.\n",
    "\n",
    "        :param d_input: A host or device array.\n",
    "        :param stream: Optional CUDA stream in which to perform the scan.\n",
    "                    If no stream is specified, the default stream of 0 is used.\n",
    "        \"\"\"\n",
    "        # ensure 1d array\n",
    "        if d_input.ndim != 1:\n",
    "            raise TypeError(\"only support 1D array\")\n",
    "\n",
    "        # ensure size > 0\n",
    "        if d_input.size < 1:\n",
    "            raise ValueError(\"array's length is 0\")\n",
    "\n",
    "        # ensure arrays' size are the same\n",
    "        if d_input.size != d_output.size:\n",
    "            raise ValueError(\"arrays' length are different ({d_input.size} / {d_output.size}\")\n",
    "\n",
    "        # ensure size < 256\n",
    "        max_block_size = BlockScanHybrid._WARP_SIZE * BlockScanHybrid._NUM_WARPS\n",
    "        if d_input.size < max_block_size:\n",
    "            raise ValueError(\"array's `length is greater than max block size\")\n",
    "\n",
    "        _sav, core.config.CUDA_LOW_OCCUPANCY_WARNINGS = core.config.CUDA_LOW_OCCUPANCY_WARNINGS, False\n",
    "\n",
    "        kernel = self._compile(d_input.dtype)\n",
    "        # turn on GPU...\n",
    "        nb_threads = max_block_size\n",
    "        nb_blocks = 1\n",
    "        kernel[nb_blocks, nb_threads, stream](d_input, d_output)\n",
    "\n",
    "        # Perform the reduction on the GPU\n",
    "        start_event = cuda.event(True)\n",
    "        start_event.record(stream=stream)\n",
    "\n",
    "        nb_threads = max_block_size\n",
    "        nb_blocks = 1\n",
    "        kernel[nb_blocks, nb_threads, stream](d_input, d_output)\n",
    "\n",
    "        stop_event = cuda.event(True)\n",
    "        stop_event.record(stream=stream)\n",
    "        stop_event.synchronize()\n",
    "        ct = cuda.event_elapsed_time(start_event, stop_event)\n",
    "        print(f\"kernel computation time is {ct} ms\")\n",
    "\n",
    "        core.config.CUDA_LOW_OCCUPANCY_WARNINGS = _sav\n",
    "\n",
    "        return d_output.copy_to_host()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    def iscan(array, zero):\n",
    "        sum = zero\n",
    "        for i in range(array.size):\n",
    "            sum += array[i]\n",
    "            array[i] = sum\n",
    "\n",
    "\n",
    "    def display(array):\n",
    "        for i in range(array.size):\n",
    "            print(f\"{array[i]} \", end=\"\")\n",
    "            if (i % 16) == 15:\n",
    "                print(\"\")\n",
    "\n",
    "\n",
    "    def check(expected, result):\n",
    "        it_works = True\n",
    "        for i in range(result.size):\n",
    "            if expected[i] != result[i]:\n",
    "                it_works = False\n",
    "        if it_works:\n",
    "            print(f'- seems to work')\n",
    "        else:\n",
    "            print(f'- seems to not work, here is your result:')\n",
    "            display(result)\n",
    "\n",
    "\n",
    "    def test_int32(size):\n",
    "        scanner = BlockScanHybrid(lambda a, b: a + b)\n",
    "        h_array = np.ones(size, dtype=np.int32)\n",
    "        result = scanner(cuda.to_device(h_array), cuda.to_device(h_array))\n",
    "        iscan(h_array, np.int32(0))\n",
    "        check(h_array, result)\n",
    "\n",
    "\n",
    "    def test_float32(size):\n",
    "        scanner = BlockScanHybrid(lambda a, b: a + b)\n",
    "        h_array = np.ones(size, dtype=np.float32)\n",
    "        result = scanner(cuda.to_device(h_array), cuda.to_device(h_array))\n",
    "        iscan(h_array, np.float32(0))\n",
    "        check(h_array, result)\n",
    "\n",
    "\n",
    "    def test_float64(size):\n",
    "        scanner = BlockScanHybrid(lambda a, b: a + b)\n",
    "        h_array = np.ones(size, dtype=np.float64)\n",
    "        result = scanner(cuda.to_device(h_array), cuda.to_device(h_array))\n",
    "        iscan(h_array, np.float64(0))\n",
    "        check(h_array, result)\n",
    "\n",
    "\n",
    "    test_int32(1 << 8)\n",
    "    test_float32(1 << 8)\n",
    "    test_float64(1 << 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "33 >> 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "In this exercise you must implement the **full scan** for a given binary associative operator.\n",
    "\n",
    "The lecture 3 gives you all the clue for this purpose:\n",
    "- the per block SCAN, with its extra value,\n",
    "- the inter-block extra value scan which is a recursive call,\n",
    "- the MAP to end the SCAN by adding the extra block scanned values (with shift). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan computation time is 0.01942400075495243 ms\n",
      "- seems to not work, here is your result:\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "...\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "...\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "...\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "...\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "...\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \n",
      "...\n",
      "241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 \n",
      "257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 \n",
      "...\n",
      "497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 \n",
      "513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 \n",
      "...\n",
      "753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 \n",
      "769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 \n",
      "...\n",
      "16776945 16776946 16776947 16776948 16776949 16776950 16776951 16776952 16776953 16776954 16776955 16776956 16776957 16776958 16776959 16776960 \n",
      "16776961 16776962 16776963 16776964 16776965 16776966 16776967 16776968 16776969 16776970 16776971 16776972 16776973 16776974 16776975 16776976 \n",
      "...\n",
      "16777201 16777202 16777203 16777204 16777205 16777206 16777207 16777208 16777209 16777210 16777211 16777212 16777213 16777214 16777215 16777216 \n",
      "scan computation time is 0.020160000771284103 ms\n",
      "- seems to not work, here is your result:\n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "...\n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "...\n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "...\n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "...\n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "...\n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.0 11.0 12.0 13.0 14.0 15.0 16.0 \n",
      "...\n",
      "241.0 242.0 243.0 244.0 245.0 246.0 247.0 248.0 249.0 250.0 251.0 252.0 253.0 254.0 255.0 256.0 \n",
      "257.0 258.0 259.0 260.0 261.0 262.0 263.0 264.0 265.0 266.0 267.0 268.0 269.0 270.0 271.0 272.0 \n",
      "...\n",
      "497.0 498.0 499.0 500.0 501.0 502.0 503.0 504.0 505.0 506.0 507.0 508.0 509.0 510.0 511.0 512.0 \n",
      "513.0 514.0 515.0 516.0 517.0 518.0 519.0 520.0 521.0 522.0 523.0 524.0 525.0 526.0 527.0 528.0 \n",
      "...\n",
      "753.0 754.0 755.0 756.0 757.0 758.0 759.0 760.0 761.0 762.0 763.0 764.0 765.0 766.0 767.0 768.0 \n",
      "769.0 770.0 771.0 772.0 773.0 774.0 775.0 776.0 777.0 778.0 779.0 780.0 781.0 782.0 783.0 784.0 \n",
      "...\n",
      "16776945.0 16776946.0 16776947.0 16776948.0 16776949.0 16776950.0 16776951.0 16776952.0 16776953.0 16776954.0 16776955.0 16776956.0 16776957.0 16776958.0 16776959.0 16776960.0 \n",
      "16776961.0 16776962.0 16776963.0 16776964.0 16776965.0 16776966.0 16776967.0 16776968.0 16776969.0 16776970.0 16776971.0 16776972.0 16776973.0 16776974.0 16776975.0 16776976.0 \n",
      "...\n",
      "16777201.0 16777202.0 16777203.0 16777204.0 16777205.0 16777206.0 16777207.0 16777208.0 16777209.0 16777210.0 16777211.0 16777212.0 16777213.0 16777214.0 16777215.0 16777216.0 \n",
      "scan computation time is 0.01894400082528591 ms\n",
      "- seems to not work, here is your result:\n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "...\n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "...\n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "...\n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "...\n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "...\n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.0 11.0 12.0 13.0 14.0 15.0 16.0 \n",
      "...\n",
      "241.0 242.0 243.0 244.0 245.0 246.0 247.0 248.0 249.0 250.0 251.0 252.0 253.0 254.0 255.0 256.0 \n",
      "257.0 258.0 259.0 260.0 261.0 262.0 263.0 264.0 265.0 266.0 267.0 268.0 269.0 270.0 271.0 272.0 \n",
      "...\n",
      "497.0 498.0 499.0 500.0 501.0 502.0 503.0 504.0 505.0 506.0 507.0 508.0 509.0 510.0 511.0 512.0 \n",
      "513.0 514.0 515.0 516.0 517.0 518.0 519.0 520.0 521.0 522.0 523.0 524.0 525.0 526.0 527.0 528.0 \n",
      "...\n",
      "753.0 754.0 755.0 756.0 757.0 758.0 759.0 760.0 761.0 762.0 763.0 764.0 765.0 766.0 767.0 768.0 \n",
      "769.0 770.0 771.0 772.0 773.0 774.0 775.0 776.0 777.0 778.0 779.0 780.0 781.0 782.0 783.0 784.0 \n",
      "...\n",
      "16776945.0 16776946.0 16776947.0 16776948.0 16776949.0 16776950.0 16776951.0 16776952.0 16776953.0 16776954.0 16776955.0 16776956.0 16776957.0 16776958.0 16776959.0 16776960.0 \n",
      "16776961.0 16776962.0 16776963.0 16776964.0 16776965.0 16776966.0 16776967.0 16776968.0 16776969.0 16776970.0 16776971.0 16776972.0 16776973.0 16776974.0 16776975.0 16776976.0 \n",
      "...\n",
      "16777201.0 16777202.0 16777203.0 16777204.0 16777205.0 16777206.0 16777207.0 16777208.0 16777209.0 16777210.0 16777211.0 16777212.0 16777213.0 16777214.0 16777215.0 16777216.0 \n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "from numba.np.numpy_support import from_dtype\n",
    "from numba import cuda, core\n",
    "\n",
    "\n",
    "def display(array, all_values=False):\n",
    "    def aprint(data_range, noend=False):\n",
    "        for i in data_range:\n",
    "            print(f\"{array[i]} \", end=\"\")\n",
    "            if (i % 16) == 15: print(\"\")\n",
    "        if not noend: print(\"...\")\n",
    "\n",
    "    if all_values:\n",
    "        aprint(range(array.size), noend=True)\n",
    "        return\n",
    "    aprint(range(0, min(array.size, 16)))\n",
    "    if array.size < 256 - 16: return\n",
    "    aprint(range(256 - 16, min(array.size, 256 + 16)))\n",
    "    if array.size < 512 - 16: return\n",
    "    aprint(range(512 - 16, min(array.size, 512 + 16)))\n",
    "    if array.size < 768 - 16: return\n",
    "    aprint(range(768 - 16, min(array.size, 768 + 16)))\n",
    "    aprint(range(array.size - 16 - 256, array.size - 256 + 16))\n",
    "    aprint(range(array.size - 16, array.size), noend=True)\n",
    "\n",
    "\n",
    "class InclusiveScan(object):\n",
    "    \"\"\"Create a scan object that scans values using a given binary\n",
    "    function. The binary function is compiled once and cached inside this\n",
    "    object. Keeping this object alive will prevent re-compilation.\n",
    "\n",
    "    The scan is functional for a limited number of values, as it runs into a single block.\n",
    "    THe number of values should be less than 256.\n",
    "    \"\"\"\n",
    "\n",
    "    _kernels_block_scan = {}\n",
    "    _kernels_block_map = {}\n",
    "\n",
    "    _WARP_SIZE = 32\n",
    "    _NUM_WARPS = 8\n",
    "\n",
    "    @staticmethod\n",
    "    def _gpu_kernel_block_scan_factory(fn, np_type):\n",
    "        \"\"\"Factory of kernels for the block-scan problem...\n",
    "\n",
    "        This function returns a Cuda Kernel that does block-scan of some data using a given binary functor.\"\"\"\n",
    "\n",
    "        scan_op = cuda.jit(device=True)(fn)\n",
    "\n",
    "        max_block_size = InclusiveScan._NUM_WARPS * InclusiveScan._WARP_SIZE\n",
    "\n",
    "        @cuda.jit(device=True)\n",
    "        def load_shared_memory(shared_memory, d_input):\n",
    "            local_tid = cuda.threadIdx.x\n",
    "            tid = cuda.grid(1)\n",
    "            if tid < d_input.size:\n",
    "                shared_memory[local_tid] = d_input[local_tid]\n",
    "            cuda.syncthreads()\n",
    "\n",
    "        @cuda.jit(device=True)\n",
    "        def pointer_jumping(shared_memory, jump):\n",
    "            tid = cuda.threadIdx.x\n",
    "            # TODO: implement the pointer jumping (full block)\n",
    "            right = local_tid + jump\n",
    "            if right < max_block_size: #cuda.blockDim.x\n",
    "                temp = shared_memory[right]\n",
    "            else:\n",
    "                temp = shared_memory[local_tid]\n",
    "            cuda.syncthreads()\n",
    "            if right < max_block_size:\n",
    "                shared_memory[local_tid] = scan_op(temp, shared_memory[local_tid])\n",
    "            cuda.syncthreads()\n",
    "\n",
    "        @cuda.jit(device=True)\n",
    "        def save_shared_memory(shared_memory, d_output, d_extras):\n",
    "            local_tid = cuda.threadIdx.x\n",
    "            global_tid = cuda.grid(1)\n",
    "            # TODO: save data from shared memory\n",
    "            if global_tid < d_output.size:\n",
    "                d_output[local_tid] = shared_memory[local_tid]\n",
    "            \n",
    "            # TODO: save last block value to \"d_extras\"!\n",
    "            if local_tid == 0:\n",
    "                \n",
    "            \n",
    "        def gpu_scan_block(d_input, d_output, d_extras):\n",
    "            \"\"\"\n",
    "            Per block SCAN...\n",
    "            \"\"\"\n",
    "            # move data to shared memory\n",
    "            shared_memory = cuda.shared.array(shape=max_block_size, dtype=np_type)\n",
    "            load_shared_memory(shared_memory, d_input)\n",
    "\n",
    "            # TODO: implements the logics\n",
    "            pointer_jumping(shared_memory, 1)\n",
    "\n",
    "            # now stores the result\n",
    "            save_shared_memory(shared_memory, d_output, d_extras)\n",
    "\n",
    "        return cuda.jit(gpu_scan_block)\n",
    "\n",
    "    def __init__(self, functor):\n",
    "        \"\"\"\n",
    "        :param functor: A function implementing a binary operation for\n",
    "                        scan. It will be compiled as a CUDA device\n",
    "                        function using ``cuda.jit(device=True)``.\n",
    "        \"\"\"\n",
    "        self._functor = functor\n",
    "\n",
    "    def _compile_block_scan(self, dtype):\n",
    "        key = self._functor, dtype\n",
    "        if key not in self._kernels_block_scan:\n",
    "            self._kernels_block_scan[key] = InclusiveScan._gpu_kernel_block_scan_factory(self._functor,\n",
    "                                                                                         from_dtype(dtype))\n",
    "        return self._kernels_block_scan[key]\n",
    "\n",
    "    @staticmethod\n",
    "    def _gpu_kernel_block_map_factory(fn, np_type):\n",
    "        \"\"\"Factory of kernels for the block-map problem...\n",
    "\n",
    "        This function returns a Cuda Kernel that does block-map of some data using a given binary functor.\"\"\"\n",
    "\n",
    "        scan_op = cuda.jit(device=True)(fn)\n",
    "\n",
    "        def gpu_map_block(d_io, d_scan):\n",
    "            \"\"\"\n",
    "            Per block MAP...\n",
    "            \"\"\"\n",
    "            # TODO: implements the logics\n",
    "\n",
    "        return cuda.jit(gpu_map_block)\n",
    "\n",
    "    def _compile_block_map(self, dtype):\n",
    "        key = self._functor, dtype\n",
    "        if key not in self._kernels_block_map:\n",
    "            self._kernels_block_map[key] = InclusiveScan._gpu_kernel_block_map_factory(self._functor, from_dtype(dtype))\n",
    "        return self._kernels_block_map[key]\n",
    "\n",
    "    def __call__(self, d_input, d_output, stream=cuda.default_stream()):\n",
    "        \"\"\" Performs a per-block SCAN.\n",
    "\n",
    "        :param d_input: A host or device array.\n",
    "        :param stream: Optional CUDA stream in which to perform the scan.\n",
    "                    If no stream is specified, the default stream of 0 is used.\n",
    "        \"\"\"\n",
    "\n",
    "        # ensure 1d array\n",
    "        if d_input.ndim != 1:\n",
    "            raise TypeError(\"only support 1D array\")\n",
    "\n",
    "        # ensure size > 0\n",
    "        if d_input.size < 1:\n",
    "            raise ValueError(\"array's length is 0\")\n",
    "\n",
    "        # ensure arrays' size are the same\n",
    "        if d_input.size != d_output.size:\n",
    "            raise ValueError(\"arrays' length are different ({d_input.size} / {d_output.size}\")\n",
    "\n",
    "        _sav, core.config.CUDA_LOW_OCCUPANCY_WARNINGS = core.config.CUDA_LOW_OCCUPANCY_WARNINGS, False\n",
    "\n",
    "        kernel_step1 = self._compile_block_scan(d_input.dtype)\n",
    "        kernel_step2 = self._compile_block_map(d_input.dtype)\n",
    "\n",
    "        max_block_size = InclusiveScan._WARP_SIZE * InclusiveScan._NUM_WARPS\n",
    "        nb_threads = min(max_block_size, d_input.size)\n",
    "        nb_blocks = (d_input.size + nb_threads - 1) // nb_threads\n",
    "        extras = cuda.device_array(shape=nb_blocks, dtype=d_input.dtype)\n",
    "\n",
    "        # Perform the reduction on the GPU\n",
    "        start_event = cuda.event(True)\n",
    "        start_event.record(stream=stream)\n",
    "\n",
    "        # TODO implement the logics\n",
    "\n",
    "        stop_event = cuda.event(True)\n",
    "        stop_event.record(stream=stream)\n",
    "        stop_event.synchronize()\n",
    "\n",
    "        core.config.CUDA_LOW_OCCUPANCY_WARNINGS = _sav\n",
    "\n",
    "        # display(extras)\n",
    "\n",
    "        return cuda.event_elapsed_time(start_event, stop_event)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    def check(expected, result):\n",
    "        it_works = np.array_equal(expected, result)\n",
    "        if it_works:\n",
    "            print(f'- seems to work')\n",
    "        else:\n",
    "            print(f'- seems to not work, here is your result:')\n",
    "            display(result)\n",
    "            display(expected)\n",
    "\n",
    "\n",
    "    def test_int32(size):\n",
    "        scanner = InclusiveScan(lambda a, b: a + b)\n",
    "        h_array = np.ones(size, dtype=np.int32)\n",
    "        d_result = cuda.device_array(size, dtype=np.int32)\n",
    "        scanner(cuda.to_device(h_array), d_result)  # turn on gpu\n",
    "        ct = scanner(cuda.to_device(h_array), d_result)\n",
    "        print(f\"scan computation time is {ct} ms\")\n",
    "        expected = np.cumsum(h_array)\n",
    "        check(expected, d_result.copy_to_host())\n",
    "\n",
    "\n",
    "    def test_float32(size):\n",
    "        scanner = InclusiveScan(lambda a, b: a + b)\n",
    "        h_array = np.ones(size, dtype=np.float32)\n",
    "        d_result = cuda.device_array(size, dtype=np.float32)\n",
    "        scanner(cuda.to_device(h_array), d_result)  # turn on gpu\n",
    "        ct = scanner(cuda.to_device(h_array), d_result)\n",
    "        print(f\"scan computation time is {ct} ms\")\n",
    "        expected = np.cumsum(h_array)\n",
    "        check(expected, d_result.copy_to_host())\n",
    "\n",
    "\n",
    "    def test_float64(size):\n",
    "        scanner = InclusiveScan(lambda a, b: a + b)\n",
    "        h_array = np.ones(size, dtype=np.float64)\n",
    "        d_result = cuda.device_array(size, dtype=np.float64)\n",
    "        scanner(cuda.to_device(h_array), d_result)  # turn on gpu\n",
    "        ct = scanner(cuda.to_device(h_array), d_result)\n",
    "        print(f\"scan computation time is {ct} ms\")\n",
    "        expected = np.cumsum(h_array)\n",
    "        check(expected, d_result.copy_to_host())\n",
    "\n",
    "\n",
    "    test_int32(1 << 24)\n",
    "    # with float32, the sequential cumsum fails with more than 2^24 number...\n",
    "    test_float32(1 << 24)\n",
    "    test_float64(1 << 24)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9b4d75ac280b6c7c3aa43866cb82dc88915409b55fec83a093dd0284cb58708e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
